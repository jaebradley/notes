# Chapter 8. A Closer Look at Processes and Resource Utilization

## Tracking Processes

* `top` program displays the current system status as well as many of the fields in a `ps` listing and it updates the display ever second
  * `top` shows the most active processes (those currently taking up the most CPU time)
* On mac, can sort top by % cpu, time, pid, etc

## Finding Open Files with lsof

* `lsof` lists open files and the processes using them (it can also list network resources, dynamic libraries, pipes, etc)
* `lsof` diplays things like the command name for the process that holds the file descriptor, the process id, the user running the process, the file descriptor, the file type, the device that holds the file, the file's size, the file's inode number, and the filename

### Using lsof

* Pipe `lsof` output to `less` and then search for what you're looking for and/or narrow down what `lsof` returns by specifying command-line options
  * `lsof /usr` would only display entires for open files in `/usr`
  * `lsof -p some_process_id` would only list the open files for a particular process id

## Threads

* In Linux, some processes are divided into pieces called threads
* A thread is similar to a process (it has an id, and the kernel schedules and runs threads just like processes)
  * However, all threads within a single process share system resources like memory and I/O connections 
* The primary advantage of a multithreaded process is that when the process has a lot to do, threads can run simulatenously on multiple processors
  * A CPU can have multiple processors, all threads are executed within a single CPU
  * Multiprocessing uses two or more CPUs
* Although you can achieve simulatenous computation with multiple processes, threads start faster than processes, and it is often easier and/or more efficient for threads to intercommunicate using their shared memory

## Measuring CPU Time

* Use `top` + `-p` (or `-pid` on Mac) option that specifies a process id
* To find out how much CPU time a command uses during its lifetime use `time` (`usr/bin/time`)
* `time ls` will output "real", "user", and "system"
  * User time is the number of seconds that the CPU spent running the program's own code
  * System time is the amount of time the kernel spends doing the process's work
  * Elapsed time is the total time it took to run the process from start to finish, including the time that the CPU spent doing other tasks
    * Subtracting the user and system time from the elapsed time can give a general idea of how long a process spends waiting for system resources

### Using uptime

* The `uptime` command tells you three load averages in addition to how long the kernel has been running
* The three load average numbers outputted by the command are the load averages for the past 1 minute, 5 minutes, and 15 minutes
  * The load averages is the average number of processes that have been running across all processors for that duration

## Memory

* The CPU has a memory management unit that translates the virtual memory addresses used by processes into real ones
* The kernel assists the MMU by breaking the memory used by processes into smaller chunks called pages
* The kernel maintains a data structure called a page table that contains a mapping of processes' virtual page addresses to real page addresses in memory
* As a process accesses memory, the MMU translates the virtual addresses used by the process into real addresses based on the kernel's page table
* Consider how a program starts and runs as a new process
  * The kernel loads the beginning of the program's instruction code into memory pages
  * The kernel may allocate some working-memory pages to the new process
  * As the process runs, it might reach a point where the next instruction in its code isn't in any of the pages that the kernel initially loaded
  * At this point, the kernel takes over, loads the necessary pages into memory, and then lets the program resume execution
  * If the program requires more working memory than was initially allocated, the kernel handles it by finding free pages (or by making room)

### Page Faults

* If a memory page is not ready when a process wants to use it, the process triggers a page fault
* in the event of a page fault, the kernel takes control of the CPU from the process in order to get the page ready

#### Minor Page Faults

* Occurs when the desired page is actually in main memory, but the MMU doesn't know where it is
* This can happen when the process requests more memory or when the MMU doesn't have enough space to store all of the page locations for a process
* The kernel tells the MMU about the page and permits the process to continue

#### Major Page Faults

* Occurs when the desired memory page isn't in main memory at all, which means that the kernel must load it from disk or some other slow storage mechanism
* Kernel must do substantial amount of work to provide the pages, causing dealys for other processes
* Some major page faults are unavoidable, such as those that occur when you load code from disk when running a program for the first time
* The biggest problems happen when you start running out of memory and the kernel starts to swap pages of working memory out to the disk in order to make room for new pages
