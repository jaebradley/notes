# 4.4 Threading Issues

## 4.4.1 The `fork()` and `exec()` System Calls
* Some UNIX systems implement two versions of `fork()`, one that duplicates all threads in the process, and another that duplicates only the thread that invoked the `fork()` system call
* If a thread invokes the `exec()` system call, the pgoram specified in the parameter to `exec()` will replace the entire process - including all threads

## 4.4.3 Signal Handling
* A signal is generated by the occurrence of a particular event
* A generated signal is delivered to a process
* Once delivered,t he signal must be handled
* Synchronous signals (illegal memory access, division by 0) are delivered to the same process that performed the operation
* When a signal is generated by an event external to a running process, that process receives the signal asynchronously
  * Terminating a process with specific keystrokes (control + c) or having a timer expire
* Every signal has a default signal handler that is fun by the kernel when handling that signal
* Synchronous signals need to be delivered to the thread causing the signal and not to other threads in the process
* Some asynchronous signals, like a signal that terminates a process, should be sent to all threads
* Because signals need to be handled only once, a signal is typically delivered only to the first thread found that is not blocking it

## 4.4.4 Thread Pools
* Web server example: if all concurrent requests are serviced in a new thread, there is no bound on the number of concurrent threads
  * Unlimited threads could exhaust system resources like CPU time or memory
* Thread pools create a number of threads at process startup, place them into a pool, where they sit and wait for work
  * Server waits until a thread becomes free
  * Using an existing thread is usually faster than creating a new thread
  * Limits the number of threads that can exist at any one point, which is important for systems that cannot support a large number of concurrent threads

## 4.4.6 Scheduler Activations
* Implemented by systems using the many-to-many or the two-level model for user space and kernel threads
* Data structure between user and kernel threads called lightweight process
* To the user-thread library, the LWP appears to be a virtual processor which the application can schedule a user thread to run
* Each LWP is associated with a kernel thread
* The operating system schedules the kernel threads to run on physical processors
* If a kernel thread blocks (waiting for an I/O operation to complete), the LWP blocks, and the user-level thread will also block
* Typically, an LWP is required for each concurrent blocking system call
* Scheduler activation works by having the kernel supply an application with a set of LWPs to schedule user threads on
  * The kernel informs the application about certain events via "upcalls"
  * Upcalls are handled by the thread library via an upcall handlers, and upcall handlers must run on a LWP
  * An upcall is triggered right before an application thread is about to block
  * In this scenario, the kernel makes an upcall to the application informing it that a thread is about to block, identifying the specific thread
  * Kernel allocates a new LWP to the application
  * Application runs upcall handler on newly allocated LWP
  * Upcall handler schedules another thread that will run on newly allocated LWP
  * When blocking thread is unblocked, kernel makes another upcall to the thread library informing it that previously blocked thread can run
    * This event may require a LWP to process the upcall event, so kernel may allocate another LWP or preempt one of the user threads and run the upcall handler on its LWP
  * Application schedules the eligible thread to run on an available LWP
